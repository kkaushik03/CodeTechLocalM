# ğŸ§  CodeTech Backend

AI-Powered Code Grading System â€” Backend Only (Ollama Edition)

CodeTech is a backend-only project that automates code grading using a local large language model (LLM) via [Ollama](https://ollama.com). Upload your source code files and get back detailed, structured feedback on correctness, efficiency, readability, and more â€” all without relying on external APIs like OpenAI.

---

## ğŸš€ Features

- ğŸ” Secure File Upload API (supports `.py`, `.js`, etc.)
- âš™ï¸ Code Evaluation via Local LLM (Mistral / LLaMA3 using Ollama)
- ğŸ“ Auto-generated HTML/JSON Reports with grading feedback
- ğŸ“‚ Report download & file handling system
- ğŸ” REST API with clean, testable architecture
- ğŸ§ª Ready to demo via Postman or cURL â€” no frontend required

---

## ğŸ§° Tech Stack

| Layer         | Tech                     |
|--------------|--------------------------|
| Language      | Python / JavaScript     |
| Framework     | Flask / Express         |
| LLM Backend   | Ollama (Mistral, LLaMA) |
| File Handling | Multer / Flask-Uploads  |
| Report Output | HTML / JSON / PDF       |

---

## ğŸ“¦ Setup Instructions

### 1. Clone the Repo
```bash
git clone https://github.com/your-username/codetech-backend.git
cd codetech-backend
```

### 2. Install Ollama & Run Model
```bash
brew install ollama           # or follow Linux instructions
ollama run mistral            # or llama2/llama3
```

### 3. Install Dependencies
```bash
# Python (Flask)
pip install -r requirements.txt

# Node.js (Express)
npm install
```

### 4. Run the Server
```bash
# Python
flask run

# Node
npm start
```

---

## ğŸ“¡ API Endpoints

| Method | Route            | Description                            |
|--------|------------------|----------------------------------------|
| POST   | `/upload`        | Upload code file for grading           |
| POST   | `/grade`         | Analyze code and return report         |
| GET    | `/report/:id`    | Fetch specific grading report          |
| POST   | `/feedback`      | Submit feedback (optional)             |

---

## ğŸ“‹ Sample Prompt to LLM
```text
Please grade the following Python code based on:
- Correctness
- Efficiency
- Readability
- Style
- Security
- Fragility

Also provide brief feedback for each section.

<INSERT CODE HERE>
```

---

## ğŸ§ª Testing the API (via Postman)
- Upload your `.py` file to `/upload`
- Use the returned file path in `/grade`
- View or download the HTML report via `/report/:id`

---

## ğŸ¤ Team

- **Khushi Kaushik** â€“ Project Manager, AI/ML Integration  
- **Alyssa Amancio** â€“ File Systems, Architecture  
- **Trang Ngo** â€“ LLM Prompt Engineering, Report Generation

---

## ğŸ§  Stretch Goals

- âš¡ Offline-first local LLM performance improvements
- ğŸ“Š Add scoring customization and rubrics
- ğŸ” JWT Authentication and user dashboard
- ğŸ•¸ï¸ GitHub integration for pull request grading

---

## ğŸ“ƒ License
This project is for educational/demo purposes only.

---

## ğŸ’¬ Feedback
Have suggestions? Submit them to `/feedback` or open an issue!

Happy grading! ğŸ§ ğŸ’»
